# -*- coding: utf-8 -*-
"""USVA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11MJLo7f8Po_op2QVqhDqDlgedYSp8QtG

#**2020 US Election tweets analysis**
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# stopwords, tokenizer, stemmer
import nltk  
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer
from nltk.probability import FreqDist

# spell correction, lemmatization
from textblob import TextBlob
from textblob import Word

from PIL import Image
import plotly.express as px

trump_df = pd.read_csv('hashtag_donaldtrump.csv', lineterminator='\n')
biden_df = pd.read_csv('hashtag_joebiden.csv', lineterminator='\n')

trump_df['tweet'].head(10)

biden_df['tweet'].head(10)

trump_df = trump_df.drop(columns=['tweet_id','user_id','user_name','user_screen_name',
                                  'user_description','user_join_date','collected_at','created_at','source','lat','long','state_code'])
biden_df = biden_df.drop(columns=['tweet_id','user_id','user_name','user_screen_name',
                                  'user_description','user_join_date','collected_at','created_at','source','lat','long','state_code'])

# Renaming columns
trump_df = trump_df.rename(columns={"likes": "Likes", "retweet_count": "Retweets", 
                                    "state": "State", "user_followers_count": "Followers"})
biden_df = biden_df.rename(columns={"likes": "Likes", "retweet_count": "Retweets", 
                                    "state": "State", "user_followers_count": "Followers"})

# Update United States country name for consistency
d = {"United States of America":"United States"}
trump_df['country'].replace(d, inplace=True)
biden_df['country'].replace(d, inplace=True)

trump_df = trump_df.loc[trump_df['country'] == "United States"]
biden_df = biden_df.loc[biden_df['country'] == "United States"]

# Drop null rows
trump_df = trump_df.dropna()
biden_df = biden_df.dropna()

trump_df

biden_df

to_remove = r'\d+|http?\S+|[^A-Za-z0-9]+'
nltk.download('stopwords')
nltk.download('punkt')
stop_words = set(stopwords.words('english'))
ps = PorterStemmer()

# Function to preprocess tweet 
def clean_tweet(tweet, stem=False, lemmatize=False):

    # Make all text lowercase
    tweet = tweet.lower()
    
    # Remove links, special characters, punctuation, numbers, etc.
    tweet = re.sub(to_remove, ' ', tweet)
        
    filtered_tweet = []
    words = word_tokenize(tweet) 

    # Remove stopwords and stem
    for word in words:
        if not word in stop_words:
            if stem:
                filtered_tweet.append(ps.stem(word))
            elif lemmatize:
                filtered_tweet.append(Word(word).lemmatize())
            else:
                filtered_tweet.append(word)
            
    return filtered_tweet

trump_df['tweet'] = trump_df.tweet.apply(lambda x: clean_tweet(x))
biden_df['tweet'] = biden_df.tweet.apply(lambda x: clean_tweet(x))

def sentiment_analysis_Trump_df(df):
    
    # Determine polarity and subjectivity
    df['Polarity'] = df['tweet'].apply(lambda x: TextBlob(' '.join(x)).sentiment.polarity)
    df['Subjectivity'] = df['tweet'].apply(lambda x: TextBlob(' '.join(x)).sentiment.subjectivity)
    
    # Classify overall sentiment
    df.loc[df.Polarity > 0,'Sentiment'] = 'EVT'#Expected Vote for Trump
    df.loc[df.Polarity == 0,'Sentiment'] = 'ENV'#Expected No Vote for Either candidates
    df.loc[df.Polarity < 0,'Sentiment'] = 'EVB'#Expected Vote for Biden
    
    return df

trump_df=sentiment_analysis_Trump_df(trump_df)

trump_df=trump_df.reset_index()

trump_df=trump_df.drop(columns=['index'])
trump_df

def sentiment_analysis_biden_df(df):
    
    # Determine polarity and subjectivity
    df['Polarity'] = df['tweet'].apply(lambda x: TextBlob(' '.join(x)).sentiment.polarity)
    df['Subjectivity'] = df['tweet'].apply(lambda x: TextBlob(' '.join(x)).sentiment.subjectivity)
    
    # Classify overall sentiment
    df.loc[df.Polarity > 0,'Sentiment'] = 'EVB'#Expected Vote for Biden
    df.loc[df.Polarity == 0,'Sentiment'] = 'ENV'#Expected No Vote for Either candidates
    df.loc[df.Polarity < 0,'Sentiment'] = 'EVT'#Expected Vote for Trump
    
    return df

biden_df=sentiment_analysis_biden_df(biden_df)

biden_df=biden_df.reset_index()

biden_df=biden_df.drop(columns=['index'])
biden_df

print("Trump Tweet Sentiment Breakdown")

trump_positive = len(trump_df.loc[trump_df.Sentiment=='EVT'])
trump_neutral = len(trump_df.loc[trump_df.Sentiment=='ENV'])
trump_negative = len(trump_df.loc[trump_df.Sentiment=='EVB'])

# Graphing the number of trump tweets by sentiment
data_t = {'EVT':trump_positive,'ENV':trump_neutral,'EVB':trump_negative}
sentiment_t = list(data_t.keys()) 
num_tweets_t = list(data_t.values()) 

plt.figure(figsize = (8, 5)) 

plt.bar(sentiment_t, num_tweets_t, color ='red', width = 0.5, edgecolor='black',) 

plt.xlabel("Sentiment", fontweight ='bold') 
plt.ylabel("Number of Tweets", fontweight ='bold') 
plt.title("Trump Tweets by Sentiment", fontweight ='bold') 
plt.show()

print("Biden Tweet Sentiment Breakdown")

biden_positive = len(biden_df.loc[biden_df.Sentiment=='EVB'])
biden_neutral = len(biden_df.loc[biden_df.Sentiment=='ENV'])
biden_negative = len(biden_df.loc[biden_df.Sentiment=='EVT'])

# Graphing the number of biden tweets by sentiment
data_b = {'EVB':biden_positive,'ENV':biden_neutral,'EVT':biden_negative}
sentiment_b = list(data_b.keys()) 
num_tweets_b = list(data_b.values()) 

plt.figure(figsize = (8, 5)) 

plt.bar(sentiment_b, num_tweets_b, color ='blue', width = 0.5, edgecolor='black') 

plt.xlabel("Sentiment", fontweight ='bold') 
plt.ylabel("Number of Tweets", fontweight ='bold') 
plt.title("Biden Tweets by Sentiment", fontweight ='bold') 
plt.show()

total_tweets_t = len(trump_df.Sentiment)
prop_tweets_t = list(map(lambda x: round(x/total_tweets_t,2), num_tweets_t))

# Calculate relative percentages by sentiment - Biden
total_tweets_b = len(biden_df.Sentiment)
prop_tweets_b = list(map(lambda x: round(x/total_tweets_b,2), num_tweets_b))

# Graphing relative percentages of both trump and biden tweets
bar_width = 0.25
plt.subplots(figsize=(8,8))

br1 = np.arange(3) 
br2 = [x + bar_width for x in br1] 

t = plt.bar(br1, prop_tweets_t, color ='r', width = bar_width, 
            edgecolor ='black', label ='Trump') 
b = plt.bar(br2, prop_tweets_b, color ='b', width = bar_width, 
            edgecolor ='black', label ='Biden') 
   
plt.xlabel('Sentiment',fontweight ='bold') 
plt.ylabel('Percentage of Tweets',fontweight ='bold') 
plt.xticks([r + bar_width/2 for r in range(3)],['EVB','ENV','EVT'])
plt.legend([t,b],['Percentage of Trump Tweets','Percentage of Biden Tweets'])
plt.ylim(0.0, 1.0)
plt.title('Proportions of Tweets By Sentiment',fontweight ='bold')
plt.show()

trump_state_polarity = trump_df.groupby("State",as_index=False).mean()

fig = px.bar(trump_state_polarity, x="State", y="Polarity",
            title="<b>Average Polarity of Trump-Related Tweets by State</b>")
fig.update_traces(marker=dict(color="red"),selector=dict(type="bar"),
                  marker_line_color='black', marker_line_width=0.8, opacity=0.6)
fig.show()

biden_state_polarity = biden_df.groupby("State",as_index=False).mean()

fig = px.bar(biden_state_polarity, x="State", y="Polarity",
            title="<b>Average Polarity of Biden-Related Tweets by State</b>")
fig.update_traces(marker=dict(color="blue"),selector=dict(type="bar"),
                  marker_line_color='black', marker_line_width=0.8, opacity=0.6)
fig.show()

frames=[biden_df,trump_df]
df = pd.concat(frames)
df=df.drop(columns=['Likes','Retweets','Followers','city','country','continent','State','Subjectivity','Polarity','user_location'])
df

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
df['Sentiment']=le.fit_transform(df['Sentiment'])

df

stemmer=PorterStemmer()
def word_stemmer(text):
  stem_text=" ".join([stemmer.stem(i) for i in text])
  return stem_text

df['tweet']=df['tweet'].apply(lambda x:word_stemmer(x))

df

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features = 100)
X = cv.fit_transform(df['tweet']).toarray()
y=df.iloc[:,-1].values

X

print(X.shape, y.shape)

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=42)

"""**Structuring Multilayer Perceptron (MLP)  Auto Encoder model**"""

from tensorflow.keras.layers import Input
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import LeakyReLU
from tensorflow.keras.models import Model
from tensorflow.keras.utils import plot_model
n_inputs=100

"""**Encoder Layout**"""

# define encoder
visible = Input(shape=(n_inputs,))
# encoder level 1
e = Dense(n_inputs*2)(visible)
e = BatchNormalization()(e)
e = LeakyReLU()(e)
# encoder level 2
e = Dense(n_inputs)(e)
e = BatchNormalization()(e)
e = LeakyReLU()(e)
# bottleneck
n_bottleneck = n_inputs
bottleneck = Dense(n_bottleneck)(e)

"""**Decoder Layout**"""

# define decoder, level 1
d = Dense(n_inputs)(bottleneck)
d = BatchNormalization()(d)
d = LeakyReLU()(d)
# decoder level 2
d = Dense(n_inputs*2)(d)
d = BatchNormalization()(d)
d = LeakyReLU()(d)
# output layer
output = Dense(n_inputs, activation='linear')(d)
# define autoencoder model
model = Model(inputs=visible, outputs=output)

model.compile(optimizer='adam', loss='mse')

"""**Strucuture of Autoencoder**"""

plot_model(model, 'autoencoder_no_compress.png', show_shapes=True)

history = model.fit(X_train, y_train, epochs=500, batch_size=20000, verbose=2, validation_data=(X_test,y_test))

plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='test')
plt.legend()
plt.show()

encoder = Model(inputs=visible, outputs=bottleneck)
plot_model(encoder, 'encoder_no_compress.png', show_shapes=True)
# save the encoder to file
encoder.save('USVA-encoder.h5')

import tensorflow as tf
from tensorflow.keras.models import load_model

encoder = load_model('USVA-encoder.h5')
X_train_encode = encoder.predict(X_train)
X_test_encode = encoder.predict(X_test)

from sklearn.neural_network import MLPClassifier
model=MLPClassifier(alpha=0.01, batch_size=2560, epsilon=1e-08,learning_rate='adaptive', max_iter=1000)
model.fit(X_train_encode,y_train)

res = model.predict(X_test_encode)
res=np.round(res)
np.set_printoptions(precision=2)
print(res)

from sklearn.metrics import accuracy_score
print("Accuracy Score for the algorithm=>{}%".format(round(accuracy_score(y_test,res)*100),2))